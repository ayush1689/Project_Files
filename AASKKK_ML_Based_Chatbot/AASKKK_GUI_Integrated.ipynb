{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Kumar\n",
      "[nltk_data]     Ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Kumar\n",
      "[nltk_data]     Ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Kumar\n",
      "[nltk_data]     Ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Kumar\n",
      "[nltk_data]     Ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Kumar\n",
      "[nltk_data]     Ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linera regressioja\n",
      "[334]1 articles cleaned.\n",
      "[91] [56]\n",
      "['formula of Linear regression']\n",
      "['Linear Regression']\n",
      "median\n",
      "[210]1 articles cleaned.\n",
      "[29] [29]\n",
      "['Central Tendency and 3 Ms']\n",
      "['Central Tendency and 3 Ms']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import json\n",
    "import pickle\n",
    "import csv\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk.stem\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.sparse import hstack\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import string\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from IPython.display import display, HTML\n",
    "import urllib\n",
    "import gzip\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "def cleanString(review):\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    returnString = \"\"\n",
    "    sentence_token = tokenize.word_tokenize(review)\n",
    "    idx_list = []\n",
    "    for j in range(len(sentence_token)):\n",
    "        #single_sentence = tokenize.word_tokenize(sentence_token[j])\n",
    "        single_sentence=[lemmatizer.lemmatize(t) for t in sentence_token]\n",
    "        single_sentence=[word for word in single_sentence if word.lower() not in stopWords]\n",
    "        sentences_filtered = [(idx,lemmatizer.lemmatize(w.lower())) for idx,w in enumerate(single_sentence) \n",
    "                              if w.lower() not in stopWords and w.isalnum()]\n",
    "        idx_list.append([x[0] for x in sentences_filtered])\n",
    "        word_list = [x[1] for x in sentences_filtered]\n",
    "        returnString = returnString + ' '.join(word_list) + ' '\n",
    "    \n",
    "    return returnString\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def listToString(s):  \n",
    "    \n",
    "    # initialize an empty string \n",
    "    str1 = \"\"  \n",
    "    \n",
    "    # traverse in the string   \n",
    "    for ele in s:  \n",
    "        str1 += ele   \n",
    "    \n",
    "    # return string   \n",
    "    return str1  \n",
    "\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer,self).build_analyzer()\n",
    "        return lambda doc:(english_stemmer.stem(word) for word in analyzer(doc))\n",
    "    \n",
    "    \n",
    "def cleanData(string1):\n",
    "    articles = []\n",
    "    n = 1\n",
    "    for i in range(n):\n",
    "        temp_string = cleanString(string1)\n",
    "        articles.append(temp_string)\n",
    "        print(str(i+1)+' of '+str(n)+\" articles cleaned.\",end='\\r')\n",
    "    \n",
    "    return(articles)\n",
    "\n",
    "\n",
    "def predict_the_message(text,file1):\n",
    "    print(text)\n",
    "    clntxt=cleanData(text)\n",
    "    word_model = pickle.load( open( file1 + \"_word_preprocessing.sav\", \"rb\" ) )\n",
    "    char_model = pickle.load( open( file1 +  \"_char_preprocessing.sav\", \"rb\" ) )\n",
    "    svd_model = pickle.load( open( file1 + \"_SVD_preprocessing.sav\", \"rb\" ) )\n",
    "    all_features = pickle.load( open( file1 + \"train_features1_preprocessing.sav\", \"rb\" ) )\n",
    "    X_test1 = word_model.transform(clntxt)\n",
    "    X_test2 = char_model.transform(clntxt)\n",
    "    test_stack = hstack([X_test2,X_test1])\n",
    "    test_stack=svd_model.transform(test_stack)\n",
    "    #Python_corpusMLP_model\n",
    "    model = pickle.load( open( file1+\"MLP_model.sav\", \"rb\" ) )\n",
    "    best_thread = pairwise_distances_argmin(\n",
    "            X=test_stack,\n",
    "            Y=all_features,\n",
    "            metric='cosine'\n",
    "        )\n",
    "    print(best_thread)\n",
    "    y_pred_class1 = model.predict(all_features[best_thread])\n",
    "    y_pred_class2 = model.predict(test_stack)\n",
    "    print(y_pred_class1,y_pred_class2)\n",
    "    return(y_pred_class1,y_pred_class2)\n",
    "\n",
    "def enter(event=None):\n",
    "    bt.bind('<Return>',enter)\n",
    "    fr.bind('<Return>',enter)\n",
    "\n",
    "def clicked (value):\n",
    "    clearscreen()   ## to clear the screen\n",
    "    label1 = Label(root, text=value, font=(\"Verdana\", 12) )\n",
    "    label1.pack()\n",
    "\n",
    "    #Create Chat window\n",
    "    ChatLog = Text(root, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\")\n",
    "    \n",
    "    ChatLog.insert(END, \"AASKKK:  Hello!!, Please type your question \" '\\n\\n')\n",
    "    ChatLog.config(foreground=\"#442265\", font=(\"Verdana\", 12, 'bold' ),borderwidth = 5)\n",
    "\n",
    "    ChatLog.config(state=DISABLED)\n",
    "\n",
    "    #Bind scrollbar to Chat window\n",
    "    scrollbar = Scrollbar(root, command=ChatLog.yview, cursor=\"heart\")\n",
    "    ChatLog['yscrollcommand'] = scrollbar.set\n",
    "    \n",
    "    #Create the box to enter message\n",
    "    EntryBox = Text(root, bd=0, bg=\"white\",width=\"29\", height=\"5\", font=\"Arial\",borderwidth = 5)\n",
    "    #EntryBox.bind(\"<Return>\", send)\n",
    "\n",
    "    #Create Button to send message\n",
    "    SendButton = Button(root, font=(\"Verdana\",12,'bold'), text=\"AASKKK\", width=\"11\", height=4,\n",
    "                        bd=0, bg=\"#32de97\", activebackground=\"#3c9d9b\",fg='#ffffff',borderwidth = 5,\n",
    "                        command= lambda: send(EntryBox,ChatLog,value) )\n",
    "\n",
    "    #Place all components on the screen\n",
    "    scrollbar.place(x=480,y=25, height=375)\n",
    "    ChatLog.place(x=6,y=25, height=375, width=480)\n",
    "    EntryBox.place(x=5, y=403, height=65, width=353)\n",
    "    SendButton.place(x=360, y=403, height=65, width=135)\n",
    "\n",
    "\n",
    "\n",
    "def clearscreen():\n",
    "    list = root.pack_slaves()\n",
    "    for l in list:\n",
    "        l.destroy()    \n",
    "        \n",
    "def send(EntryBox,ChatLog,value):\n",
    "    msg = EntryBox.get(\"1.0\",'end-1c').strip()\n",
    "    EntryBox.delete(\"0.0\",END)\n",
    "    \n",
    "    if msg == '':\n",
    "        messagebox.showinfo(\"Alert\", \"Please enter your question and then click send\")\n",
    "        \n",
    "    elif msg != '':\n",
    "        ChatLog.config(state=NORMAL)\n",
    "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')\n",
    "        ChatLog.config(foreground=\"#442265\", font=(\"Verdana\", 12,'bold'))\n",
    "\n",
    "        res = chatbot_response(msg,value)\n",
    "        ChatLog.insert(END, \"AASKKK: \" + res + '\\n\\n')\n",
    "\n",
    "        ChatLog.config(state=DISABLED)\n",
    "        ChatLog.yview(END)\n",
    "        \n",
    "\n",
    "def chatbot_response(msg,value):\n",
    "    \n",
    "   # msg =cleanData(msg)  ##output is articals\n",
    "    \n",
    "    if value == \"Python\":\n",
    "        file1=\"Python_Corpus\"\n",
    "        output,output2= predict_the_message(msg,file1)\n",
    "        \n",
    "        label=  pickle.load( open( file1+\"_labelEncoder.sav\", \"rb\" ) )\n",
    "        className=label.classes_[output]\n",
    "        className1=label.classes_[output2]\n",
    "        print(label.classes_[output])\n",
    "        print(label.classes_[output2])\n",
    "        str1 = ''.join(className1)\n",
    "        dict_label=  pickle.load( open( file1+\"_ResponseDictionary.sav\", \"rb\" ) )\n",
    "        #dict_label[listToString(['Data Analysis'])]        \n",
    "        HardCodedResult1=dict_label[listToString(label.classes_[output])]\n",
    "        HardCodedResult2=dict_label[listToString(label.classes_[output2])]\n",
    "        \n",
    "        return(\"\\n\\n\"+str(HardCodedResult1))  \n",
    "    elif value == \"Statistics_corpus\":\n",
    "        file1=\"statistics_Corpus\"\n",
    "        output,output2= predict_the_message(msg,file1)\n",
    "        \n",
    "        label=  pickle.load( open( file1+\"_labelEncoder.sav\", \"rb\" ) )\n",
    "        className=label.classes_[output]\n",
    "        className1=label.classes_[output2]\n",
    "        print(label.classes_[output])\n",
    "        print(label.classes_[output2])\n",
    "        str1 = ''.join(className1)\n",
    "        dict_label=  pickle.load( open( file1+\"_ResponseDictionary.sav\", \"rb\" ) )\n",
    "        #dict_label[listToString(['Data Analysis'])]        \n",
    "        HardCodedResult1=dict_label[listToString(label.classes_[output])]\n",
    "        HardCodedResult2=dict_label[listToString(label.classes_[output2])]\n",
    "        \n",
    "        return(\"\\n\\n\"+str(HardCodedResult1))  \n",
    "    elif value == \"Supervised Learning\":\n",
    "        file1=\"Supervised_Learning_Corpus\"\n",
    "        output,output2= predict_the_message(msg,file1)\n",
    "        \n",
    "        label=  pickle.load( open( file1+\"_labelEncoder.sav\", \"rb\" ) )\n",
    "        className=label.classes_[output]\n",
    "        className1=label.classes_[output2]\n",
    "        print(label.classes_[output])\n",
    "        print(label.classes_[output2])\n",
    "        str1 = ''.join(className1)\n",
    "        dict_label=  pickle.load( open( file1+\"_ResponseDictionary.sav\", \"rb\" ) )\n",
    "        #dict_label[listToString(['Data Analysis'])]        \n",
    "        HardCodedResult1=dict_label[listToString(label.classes_[output])]\n",
    "        HardCodedResult2=dict_label[listToString(label.classes_[output2])]\n",
    "        \n",
    "        return(\"\\n\\n\"+str(HardCodedResult1))   \n",
    "    elif value == \"Ensemble Techniques\":\n",
    "        file1=\"Ensemble_Techniques_Corpus\"\n",
    "        output,output2= predict_the_message(msg,file1)\n",
    "        \n",
    "        label=  pickle.load( open( file1+\"_labelEncoder.sav\", \"rb\" ) )\n",
    "        className=label.classes_[output]\n",
    "        className1=label.classes_[output2]\n",
    "        print(label.classes_[output])\n",
    "        print(label.classes_[output2])\n",
    "        str1 = ''.join(className1)\n",
    "        dict_label=  pickle.load( open( file1+\"_ResponseDictionary.sav\", \"rb\" ) )\n",
    "        #dict_label[listToString(['Data Analysis'])]        \n",
    "        HardCodedResult1=dict_label[listToString(label.classes_[output])]\n",
    "        HardCodedResult2=dict_label[listToString(label.classes_[output2])]\n",
    "        \n",
    "        return(\"\\n\\n\"+str(HardCodedResult1))  \n",
    "    elif value == \"Unsupervised learning\":\n",
    "        file1=\"Unsupervised_Learning_Corpus\"\n",
    "        output,output2= predict_the_message(msg,file1)\n",
    "        \n",
    "        label=  pickle.load( open( file1+\"_labelEncoder.sav\", \"rb\" ) )\n",
    "        className=label.classes_[output]\n",
    "        className1=label.classes_[output2]\n",
    "        print(label.classes_[output])\n",
    "        print(label.classes_[output2])\n",
    "        str1 = ''.join(className1)\n",
    "        dict_label=  pickle.load( open( file1+\"_ResponseDictionary.sav\", \"rb\" ) )\n",
    "        #dict_label[listToString(['Data Analysis'])]        \n",
    "        HardCodedResult1=dict_label[listToString(label.classes_[output])]\n",
    "        HardCodedResult2=dict_label[listToString(label.classes_[output2])]\n",
    "        \n",
    "        return(\"\\n\\n\"+str(HardCodedResult1))    \n",
    "    else:\n",
    "        file1=\"Combined_Corpus\"\n",
    "        output,output2= predict_the_message(msg,file1)\n",
    "        \n",
    "        label=  pickle.load( open( file1+\"_labelEncoder.sav\", \"rb\" ) )\n",
    "        className=label.classes_[output]\n",
    "        className1=label.classes_[output2]\n",
    "        print(label.classes_[output])\n",
    "        print(label.classes_[output2])\n",
    "        str1 = ''.join(className1)\n",
    "        dict_label=  pickle.load( open( file1+\"_ResponseDictionary.sav\", \"rb\" ) )\n",
    "        #dict_label[listToString(['Data Analysis'])]        \n",
    "        HardCodedResult1=dict_label[listToString(label.classes_[output])]\n",
    "        HardCodedResult2=dict_label[listToString(label.classes_[output2])]\n",
    "\n",
    "        return(\"\\n\\n\"+str(HardCodedResult2))  \n",
    "#Description: This is a chat bot GUI\n",
    "\n",
    "\n",
    "#Import the library\n",
    "\n",
    "from tkinter import *\n",
    "from PIL import ImageTk,Image\n",
    "from tkinter import messagebox\n",
    "\n",
    "root = Tk()\n",
    "#Name of the chat Bot\n",
    "root.title(\"AASKKK\") \n",
    "#Geometry of the chat Bot\n",
    "root.geometry(\"500x600\")\n",
    "root.resizable(width=FALSE, height=FALSE)\n",
    "\n",
    "\n",
    "# Creating Background Image\n",
    "canvas=Canvas(root,width=500,height=600)\n",
    "#give this image path. image should be in png format.\n",
    "image=ImageTk.PhotoImage(Image.open(\"wall_e.png\"))\n",
    "canvas.create_image(0,0,anchor=NW,image=image)\n",
    "canvas.place(height=600, x=0, y=0)\n",
    "\n",
    "def restart():\n",
    "    \n",
    "    clearscreen()\n",
    "    #Name of the chat Bot\n",
    "    root.title(\"AASKKK\") \n",
    "    #Geometry of the chat Bot\n",
    "    root.geometry(\"500x600\")\n",
    "    root.resizable(width=FALSE, height=FALSE)\n",
    "        \n",
    "    # Creating Background Image\n",
    "    canvas=Canvas(root,width=500,height=600)\n",
    "    #give this image path. image should be in png format.\n",
    "    image=ImageTk.PhotoImage(Image.open(\"wall_e.png\"))\n",
    "    canvas.create_image(0,0,anchor=NW,image=image)\n",
    "    canvas.place(height=600, x=0, y=0)\n",
    "    \n",
    "    menubar= Menu(root) \n",
    "    filemenu = Menu(menubar, tearoff=0)\n",
    "    menubar.add_command(label=\"Exit\", command=root.destroy)\n",
    "    menubar.add_command(label=\"Restart\",command = lambda : restart())\n",
    "    \n",
    "    root.config(menu=menubar)  \n",
    "    label2 = Label(root, text=\"Welcome\", font=(\"Arial\", 20) )\n",
    "    label2.pack(padx= 20, pady =10)\n",
    "    \n",
    "    label2 = Label(root, text=\"Please select the topic from which you want to learn\", font=(\"Arial\", 15) )\n",
    "    label2.pack(padx= 20, pady =20)\n",
    "    \n",
    "    TOPICS = [(\"Python                         \",\"Python\"),\n",
    "          (\"Statistics                      \",\"Statistics\"),\n",
    "          (\"Supervised Learning      \",\"Supervised Learning\"),\n",
    "          (\"Ensemble Techniques    \",\"Ensemble Techniques\"),\n",
    "          (\"Unsupervised learning    \",\"Unsupervised learning\"),\n",
    "          (\"Not Sure about the topic\",\"All Topics\")\n",
    "         ]\n",
    "    option = StringVar()  \n",
    "    option.set(\"Python\")\n",
    "    \n",
    "    for text,topics in TOPICS:\n",
    "        r =Radiobutton(root, text = text, variable=option , value=topics, font=(\"Arial\", 15),bg=\"#49A\",activebackground=\"#3c9d9b\")\n",
    "        r.pack(fill=Y,anchor = CENTER )\n",
    "    \n",
    "    Button2 = Button(root, text=\"AASKKK\",fg='#ffffff',\n",
    "                 bg=\"#32de97\",activebackground=\"#3c9d9b\",font=(\"Arial\", 15,'bold'),padx= 30, pady =10,\n",
    "                 command = lambda : clicked(option.get()))\n",
    "    \n",
    "    Button2.pack(padx= 50, pady =30)\n",
    "    \n",
    "    root.mainloop()\n",
    "    \n",
    "menubar= Menu(root)\n",
    "filemenu = Menu(menubar, tearoff=0)\n",
    "    \n",
    "menubar.add_command(label=\"Exit\", command=root.destroy)\n",
    "menubar.add_command(label=\"Restart\",command = lambda : restart())\n",
    "    \n",
    "root.config(menu=menubar)\n",
    "    \n",
    "label2 = Label(root, text=\"Welcome\", font=(\"Arial\", 18) )\n",
    "label2.pack(padx= 20, pady =10)\n",
    "    \n",
    "label2 = Label(root, text=\"Please select the topic from which you want to learn\", font=(\"Arial\", 12) )\n",
    "    \n",
    "label2.pack(padx= 20, pady =20)\n",
    "    \n",
    "    \n",
    "TOPICS = [(\"Python                         \",\"Python\"),\n",
    "          (\"Statistics                      \",\"Statistics\"),\n",
    "          (\"Supervised Learning      \",\"Supervised Learning\"),\n",
    "          (\"Ensemble Techniques    \",\"Ensemble Techniques\"),\n",
    "          (\"Unsupervised learning    \",\"Unsupervised learning\"),\n",
    "          (\"Not Sure about the topic\",\"All Topics\")\n",
    "         ]\n",
    "    \n",
    "option = StringVar()  \n",
    "option.set(\"Python\")\n",
    "    \n",
    "    \n",
    "for text,topics in TOPICS:\n",
    "    r =Radiobutton(root, text = text, variable=option , value=topics, font=(\"Arial\", 15),bg=\"#49A\",activebackground=\"#3c9d9b\")\n",
    "    r.pack(fill=Y,anchor = CENTER )\n",
    "        \n",
    "Button2 = Button(root, text=\"Submit\",fg='#ffffff',\n",
    "                 bg=\"#32de97\",activebackground=\"#3c9d9b\",font=(\"Arial\", 15),padx= 30, pady =10,\n",
    "                 command = lambda : clicked(option.get()))\n",
    "    \n",
    "Button2.pack(padx= 50, pady =30)\n",
    "    \n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin_min\n",
    "    \n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
    "    \n",
    "    \n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
